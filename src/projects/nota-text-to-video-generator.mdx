---
title: Text to video generator
tech:
  - TypeScript
  - React
  - Next.js
  - Tailwind
  - Node
  - Express.js
  - GPT
  - Diffusion Models
company: Nota
bgColor: bg-project-nota
icon: Nota
summary: A full stack project to convert an article into a video, complete with APIs and a studio to edit and tweak the final output.
---

I was the lead developer in charge of creating a text to video generator for Nota. The ask was for a user to be able to enter in text ( e.g. an article they had written ) and have the system create a video either by using images pulled from the article or to create images using a diffusion model ( e.g. Dall-E or Stable Diffusion ). There was a lot of complexity involved in this project and we broke it apart into a few pieces which eventually all worked together to create the final video.

Firstly we created an API that would figure out which parts of the article were relevant. These parts were used to form the overarching story of the video and were also used as a base to create images. The user was able to choose from a variety of different proprietary image styles that were ultimately fed into the diffusion model to create images that aligned with the theme or brand.

With the core data points for a video in place, we then developed an API that would consume a JSON schema describing the video. This would be used to compile and render an MP4. The JSON was generated by the "studio" in which the user was able to select different video templates, update text, colours, etc.

This project had a lot of moving pieces and subsequently, a lot of complexity. But we ended up with a product that I'm super proud of. The API has proved to be flexibly enough to support many different types of videos and the studio provided to be lots of fun to build.
